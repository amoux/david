{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset + sqlite3\n",
    "\n",
    "### context management for transactions in data enviroments\n",
    "\n",
    "\n",
    "**GOAL**\n",
    "\n",
    "> * Being able to keep track of a downloads, paths (location), and the name-of-files without having to explicitly import, load, and save back-to-back repeating the same steps multiple times.\n",
    "\n",
    "*When calling e.g. the `download(video_id)` method, which can return a: `(path, file-name, and meta-info)` where the file-name is the : **`video_id`**, meta-info : **'comment_count'** (*count is available and int-value can be returned*).*\n",
    "\n",
    "\n",
    "> * The database should hold the folowing values (all the following values can be obtained from the *`david.youtube.scraper.download`* method):\n",
    "    \n",
    "- file_path : str\n",
    "\n",
    "- file_name : str\n",
    "        \n",
    "- file_meta : int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/ego/Github/david/')\n",
    "\n",
    "import os\n",
    "from os.path import exists, join, isfile\n",
    "from collections import namedtuple\n",
    "\n",
    "import dataset\n",
    "import pandas as pd\n",
    "\n",
    "from david.utils import pointer\n",
    "from david.youtube import scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connecting to a database\n",
    "\n",
    "> It is also possible to define the URL as an environment variable called `DATABASE_URL` so you can initialize database connection without explicitly passing an URL:\n",
    "\n",
    "```python\n",
    "# connecting to a SQLite database\n",
    "db = dataset.connect('sqlite:///mydatabase.db')\n",
    "```\n",
    "\n",
    "#### Storing data\n",
    "\n",
    "> To store some data you need to get a reference to a table. You don’t need to worry about whether the table already exists or not, since dataset will create it automatically:\n",
    "\n",
    "* Insert a new record.\n",
    "\n",
    "```python\n",
    "# get a reference to the table 'user'.\n",
    "table = db['user']\n",
    "table.insert(dict(name='John Doe', age=46, country='China'))\n",
    "\n",
    "# dataset will create \"missing\" columns any time you insert a dict with an unknown key.\n",
    "table.insert(dict(name='Jane Doe', age=37, country='France', gender='female'))\n",
    "```\n",
    "\n",
    "* Updating existing entries.\n",
    "\n",
    "> The list of filter columns given as the second argument filter using the values in the first column. If you don’t want to update over a particular value, just use the auto-generated id column.\n",
    "\n",
    "```python\n",
    "table.update(dict(name='John Doe', age=47), ['name'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'path': 'downloads', 'name': '4Dk3jOSbz_0', 'entries': 100},\n",
       " {'path': 'downloads', 'name': 'BmYZH7xt8sU', 'entries': 4252})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATABASE_URL = 'sqlite:///context_manager.db'\n",
    "CONTEXT_TABLE = 'context'\n",
    "\n",
    "db = dataset.connect(DATABASE_URL)\n",
    "\n",
    "# when a transaction is executed: e.g user calling scraper.downlod(some-video, count=100)\n",
    "# the following parameters are created and all three parameters are ALWAYS expected.\n",
    "\n",
    "trans_1 = dict(path='downloads', name='4Dk3jOSbz_0', entries=100) # meta = entries\n",
    "trans_2 = dict(path='downloads', name='BmYZH7xt8sU', entries=4252)\n",
    "trans_1, trans_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'path', 'name', 'entries']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pass the keyword arguments to the database and save\n",
    "# (i need to add a time of download index!)\n",
    "\n",
    "table = db[CONTEXT_TABLE]\n",
    "table.insert(trans_1)\n",
    "table.insert(trans_2)\n",
    "db.commit()\n",
    "table.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_manager.db\r\n"
     ]
    }
   ],
   "source": [
    "# creates the datable if it doest exists at the address\n",
    "%ls *.db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Transactions\n",
    "\n",
    "> You can group a set of database updates in a transaction. In that case, all updates are committed at once or, in case of exception, all of them are reverted. Transactions are supported through a context manager, so they can be used through a with statement:\n",
    "\n",
    "#### Storing data\n",
    "\n",
    "> To store some data you need to get a reference to a table. You don’t need to worry about whether the table already exists or not, since dataset will create it automatically:\n",
    "\n",
    "* Insert a new record.\n",
    "\n",
    "```python\n",
    "with dataset.connect() as tx:\n",
    "    tx['user'].insert(dict(name='John Doe', age=46, country='China'))\n",
    "\n",
    "# you can get same functionality by invoking the methods:\n",
    "# begin(), commit() and rollback() explicitly:\n",
    "\n",
    "db = dataset.connect()\n",
    "db.begin()\n",
    "try:\n",
    "    db['user'].insert(dict(name='John Doe', age=46, country='China'))\n",
    "    db.commit()\n",
    "except:\n",
    "    db.rollback()\n",
    "\n",
    "# nested transactions are supported too:\n",
    "db = dataset.connect()\n",
    "with db as tx1:\n",
    "    tx1['user'].insert(dict(name='John Doe', age=46, country='China'))\n",
    "    with db as tx2:\n",
    "        tx2['user'].insert(dict(name='Jane Doe', age=37, country='France', gender='female'))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File(path='downloads', name='vdsjhdsj11', entries=30)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "from collections import Counter\n",
    "\n",
    "def context_pointer(name: str, *args):\n",
    "    '''\n",
    "    * Creating a new pointer: returns an instance class like object.\n",
    "\n",
    "        >>> File = context_pointer('File', ['path', 'name', 'entries'])\n",
    "        >>> File.__doc__\n",
    "         'File(path, name, entries)'\n",
    "\n",
    "        >>> file = File(path='downloads', name='vdsjhdsj11', entries=30)\n",
    "         File(path='downloads', name='vdsjhdsj11', entries=30)\n",
    "    \n",
    "    * By calling the `_asdict()` method returns a dict object.\n",
    "\n",
    "        >>> file_dict = file._asdict()\n",
    "        >>> file_dict['name']\n",
    "         'vdsjhdsj11'\n",
    "    '''\n",
    "    return namedtuple(name, *args)\n",
    "\n",
    "File = context_pointer('File', ['path', 'name', 'entries'])\n",
    "\n",
    "file = File(path='downloads', name='vdsjhdsj11', entries=30)\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pending_downloads.txt', 'r', encoding='utf-8') as f:\n",
    "    videos = []\n",
    "    for line in f.readlines():\n",
    "        videos.append(line.strip('\\n'))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new table in the database\n",
    "pending = db['pending_downloads']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert all video ids into with insert many\n",
    "for vid in videos:\n",
    "    pending.insert_many([dict(video_id=vid)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2FmcHiLCwTU\n",
      "bhxhNIQBKJI\n",
      "f9573kGBtuE\n",
      "XnbCSboujF4\n",
      "ad_higXixRA\n",
      "gf_MqDBBMPI\n",
      "EcojyBV4QJ4\n",
      "R2pIutTspQA\n",
      "XOLOLrUBRBY\n",
      "seJSm-vD9OA\n",
      "pU9iJB0ATpk\n",
      "voYuH5eGlkk\n",
      "6DasnKpMyQ8\n",
      "u4ZoJKF_VuA\n",
      "Ye7FKc1JQe4\n",
      "quouML5-UZI\n",
      "pOmu0LtcI6Y\n",
      "gpST3RcbRjg\n",
      "ees_hypDprw\n",
      "jBHy3M4g9vA\n",
      "JRIPV0dPAd4\n",
      "iVpXrbZ4bnU\n",
      "HXhbnC2ooE0\n",
      "dMF2i3A9Lzw\n",
      "aI6bPspVOmU\n",
      "0SPwwpruGIA\n",
      "bKOTKHtbM54\n",
      "h0oZI-FvrFk\n"
     ]
    }
   ],
   "source": [
    "# we can now query the videos from the database.\n",
    "for vid in db['pending_downloads']:\n",
    "    print(vid['video_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = dataset.connect('sqlite:///yt_comments.db')\n",
    "comments_table = db['comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import stdout\n",
    "\n",
    "def download_batch(videoid: str, table='comments', db_url='sqlite:///yt_comments.db'):\n",
    "    count = 0\n",
    "    with dataset.connect(db_url) as db:\n",
    "        for comment in scraper._scrape_comments(videoid):\n",
    "            db[table].insert(dict(\n",
    "                cid=comment['cid'], text=comment['text'],\n",
    "                time=comment['time'], author=comment['author']\n",
    "            ))\n",
    "            count += 1\n",
    "            stdout.write('mining %d comment(s)\\r' % count)\n",
    "            stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mining 24 comment(s)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ego/anaconda3/envs/vuepoint/lib/python3.6/site-packages/dataset/table.py:218: RuntimeWarning: Changing the database schema inside a transaction in a multi-threaded environment is likely to lead to race conditions and synchronization issues.\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mining 74 comment(s)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception during reset or similar\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ego/anaconda3/envs/vuepoint/lib/python3.6/site-packages/sqlalchemy/pool/base.py\", line 680, in _finalize_fairy\n",
      "    fairy._reset(pool)\n",
      "  File \"/home/ego/anaconda3/envs/vuepoint/lib/python3.6/site-packages/sqlalchemy/pool/base.py\", line 867, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"/home/ego/anaconda3/envs/vuepoint/lib/python3.6/site-packages/sqlalchemy/engine/default.py\", line 500, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "sqlite3.ProgrammingError: SQLite objects created in a thread can only be used in that same thread. The object was created in thread id 140083100628800 and this is thread id 140083022698240.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mining 75 comment(s)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception closing connection <sqlite3.Connection object at 0x7f6768d85730>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ego/anaconda3/envs/vuepoint/lib/python3.6/site-packages/sqlalchemy/pool/base.py\", line 680, in _finalize_fairy\n",
      "    fairy._reset(pool)\n",
      "  File \"/home/ego/anaconda3/envs/vuepoint/lib/python3.6/site-packages/sqlalchemy/pool/base.py\", line 867, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"/home/ego/anaconda3/envs/vuepoint/lib/python3.6/site-packages/sqlalchemy/engine/default.py\", line 500, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "sqlite3.ProgrammingError: SQLite objects created in a thread can only be used in that same thread. The object was created in thread id 140083100628800 and this is thread id 140083022698240.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ego/anaconda3/envs/vuepoint/lib/python3.6/site-packages/sqlalchemy/pool/base.py\", line 270, in _close_connection\n",
      "    self._dialect.do_close(connection)\n",
      "  File \"/home/ego/anaconda3/envs/vuepoint/lib/python3.6/site-packages/sqlalchemy/engine/default.py\", line 506, in do_close\n",
      "    dbapi_connection.close()\n",
      "sqlite3.ProgrammingError: SQLite objects created in a thread can only be used in that same thread. The object was created in thread id 140083100628800 and this is thread id 140083022698240.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mining 1085 comment(s)\r"
     ]
    }
   ],
   "source": [
    "download_batch(video_ids=videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
